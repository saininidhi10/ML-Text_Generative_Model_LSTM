{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K8eNXujQG2o"
   },
   "source": [
    "**Name: Nidhi Rajkumar Saini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxeFtMej9vBC"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.utils import np_utils\n",
    "import re, string\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYSKPth8SUXH",
    "outputId": "aea5f06d-0e29-4784-a532-68888b1bdb09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n",
      "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.32.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.2.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1BQ0HqiSjOS"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRwMOP05-2Ps"
   },
   "source": [
    "1. **Generative Models for Text**<br>\n",
    "(a) *In this problem, we are trying to build a generative model to mimic the writing style of prominent British Mathematician, Philosopher, prolific writer, and\n",
    "political activist, Bertrand Russell.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WK7mdvx_YoO"
   },
   "source": [
    "(b) Load the following books of Bertrand Russell in text format:<br>\n",
    "*i. The Problems of Philosophy <br> ii. The Analysis of Mind <br> iii. Mysticism and Logic and Other Essays <br> iv. Our Knowledge of the External World as a Field for Scientific Method in Philosophy<br>Load the following books from The Library of Congress and convert them to text files:<br>i. The History of Western Philosophy<br> ii. The Analysis of Matter<br> iii. An Inquiry into Meaning and Truth*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msdJbu-rBSHQ"
   },
   "source": [
    "(c) **LSTM**<br>\n",
    "*Train an LSTM to mimic Russell’s style and thoughts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-E7GXBzBW4a"
   },
   "source": [
    "Concatenate your text files to create a corpus of Russell’s writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TSiLjlQTRIn",
    "outputId": "ec4863ab-2af4-4048-f2ff-00b45978f3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Bertrand Russell's famous books!!\n",
      "\n",
      "Finished reading book of length 747034 ...\n",
      "\n",
      "Finished reading book of length 412289 ...\n",
      "\n",
      "Finished reading book of length 405988 ...\n",
      "\n",
      "Finished reading book of length 514653 ...\n",
      "\n",
      "Finished reading book of length 766542 ...\n",
      "\n",
      "Total length of combined book is 2846506\n"
     ]
    }
   ],
   "source": [
    "books = ['1MzLAL9DCAsyE7MczLQhTo6U44hbJC182', '1Ovi24DG7yMKt8ttr5lQbu9mXzkZDPn8D', '1VpasnabN4DJQWcjoMUevaoo5qe8konfJ', '1r9VpB5Yxs0mVr5Tr4tNS2e8BE7ohXTMc', '1XV9CV93VaWGriEqQ5F0LmtB8RdFqExHk']\n",
    "raw_data = ''\n",
    "print(\"Reading Bertrand Russell's famous books!!\")\n",
    "for each in books:\n",
    "    download = drive.CreateFile({'id': each})\n",
    "    download.GetContentFile(each)\n",
    "    raw_text = open(each, 'r', encoding = \"utf-8\", errors='ignore').read()\n",
    "    print(\"\\nFinished reading book of length\", len(raw_text), \"...\")\n",
    "    raw_data += raw_text.lower()\n",
    "print(\"\\nTotal length of combined book is\", len(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7ev1Lbu_21I"
   },
   "source": [
    "Ignore non-ascii characters and punctuations to clean the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0a8qae4M66_"
   },
   "outputs": [],
   "source": [
    "raw_data = raw_data.encode(\"ascii\", \"ignore\")\n",
    "raw_data = raw_data.decode()\n",
    "rx = re.compile('([\\n])')\n",
    "raw_data = raw_data.translate(str.maketrans('', '', string.punctuation))\n",
    "raw_data = rx.sub('', raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ac1vfk7AFHr"
   },
   "source": [
    "Use a character-level representation for this model. Each character will be encoded into an integer using its ASCII code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qzUUuuLcNEC"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integer using its ASCII code\n",
    "chars = sorted(list(set(raw_data)))\n",
    "char_to_int = dict((c, ord(c)) for c in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mooo37l-cdP7",
    "outputId": "b35ee8c9-7fe1-4779-859e-63466fc0fb15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 32,\n",
       " '0': 48,\n",
       " '1': 49,\n",
       " '2': 50,\n",
       " '3': 51,\n",
       " '4': 52,\n",
       " '5': 53,\n",
       " '6': 54,\n",
       " '7': 55,\n",
       " '8': 56,\n",
       " '9': 57,\n",
       " 'a': 97,\n",
       " 'b': 98,\n",
       " 'c': 99,\n",
       " 'd': 100,\n",
       " 'e': 101,\n",
       " 'f': 102,\n",
       " 'g': 103,\n",
       " 'h': 104,\n",
       " 'i': 105,\n",
       " 'j': 106,\n",
       " 'k': 107,\n",
       " 'l': 108,\n",
       " 'm': 109,\n",
       " 'n': 110,\n",
       " 'o': 111,\n",
       " 'p': 112,\n",
       " 'q': 113,\n",
       " 'r': 114,\n",
       " 's': 115,\n",
       " 't': 116,\n",
       " 'u': 117,\n",
       " 'v': 118,\n",
       " 'w': 119,\n",
       " 'x': 120,\n",
       " 'y': 121,\n",
       " 'z': 122}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwIE-kf2dAM2",
    "outputId": "f5ed54d7-db0b-4584-e29a-835849d18dc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  2682224\n",
      "Total Vocab:  37\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_data)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjQiCnjnCFYe"
   },
   "source": [
    "Choose a window size, e.g., W = 100. Inputs to the network will be the first\n",
    "W − 1 = 99 characters of each sequence, and the output of the network will be the Wth character of the sequence. Basically, we are training the network to predict each character using the 99 characters that precede it. Slide the window in strides of S = 1 on the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsRF7HycdR9O",
    "outputId": "07d7359d-f4ff-414d-ff0b-26055704c502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  2682125\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 99\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_data[i:i + seq_length]\n",
    "\tseq_out = raw_data[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKsWvvkpQupn"
   },
   "outputs": [],
   "source": [
    "# for validating model later\n",
    "first_data_pt = dataX[0]\n",
    "first_res = dataY[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTU9S_-MBzsP"
   },
   "source": [
    "Rescale the integers to the range [0,1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers as its input.<br>\n",
    "Note that the output has to be encoded using a one-hot encoding scheme with\n",
    "N = 256 (or less) elements. This means that the network reads integers, but\n",
    "outputs a vector of N = 256 (or less) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOBaffArhG2L"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LkrtBb-Cvut"
   },
   "source": [
    "Use a single hidden layer for the LSTM with N = 256 (or less) memory units.<br>\n",
    "Use a Softmax output layer to yield a probability prediction for each of the\n",
    "characters between 0 and 1. This is actually a character classification problem\n",
    "with N classes. Choose log loss (cross entropy) as the objective function for\n",
    "the network (research what it means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VJWrszaluZ9"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlC1QIVdDcpf"
   },
   "source": [
    "We do not use a test dataset. We are using the whole training dataset to\n",
    "learn the probability of each character in a sequence. We are not seeking for\n",
    "a very accurate model. Instead we are interested in a generalization of the\n",
    "dataset that can mimic the gist of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_5u_8JKDmyb"
   },
   "source": [
    "Choose a reasonable number of epochs for training, considering your computational power.<br>Use model checkpointing to keep the network weights to determine each time\n",
    "an improvement in loss is observed at the end of the epoch. Find the best set\n",
    "of weights in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w802Y-02NLQU",
    "outputId": "4d104d64-cf4b-4a84-a9b2-a97edab89746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18859/18859 [==============================] - 302s 15ms/step - loss: 2.6652 - val_loss: 2.3818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.38181, saving model to weights-improvement-01-2.5723-bigger.hdf5\n",
      "Epoch 2/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 2.3937 - val_loss: 2.1479\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.38181 to 2.14788, saving model to weights-improvement-02-2.3437-bigger.hdf5\n",
      "Epoch 3/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 2.2136 - val_loss: 2.0071\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.14788 to 2.00715, saving model to weights-improvement-03-2.1833-bigger.hdf5\n",
      "Epoch 4/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 2.1060 - val_loss: 1.9301\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.00715 to 1.93010, saving model to weights-improvement-04-2.0880-bigger.hdf5\n",
      "Epoch 5/50\n",
      "18859/18859 [==============================] - 283s 15ms/step - loss: 2.0363 - val_loss: 1.8862\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.93010 to 1.88618, saving model to weights-improvement-05-2.0270-bigger.hdf5\n",
      "Epoch 6/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.9918 - val_loss: 1.8389\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.88618 to 1.83885, saving model to weights-improvement-06-1.9826-bigger.hdf5\n",
      "Epoch 7/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.9526 - val_loss: 1.8157\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.83885 to 1.81572, saving model to weights-improvement-07-1.9480-bigger.hdf5\n",
      "Epoch 8/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.9238 - val_loss: 1.7817\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.81572 to 1.78174, saving model to weights-improvement-08-1.9195-bigger.hdf5\n",
      "Epoch 9/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.8993 - val_loss: 1.7567\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.78174 to 1.75674, saving model to weights-improvement-09-1.8945-bigger.hdf5\n",
      "Epoch 10/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.8768 - val_loss: 1.7435\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.75674 to 1.74349, saving model to weights-improvement-10-1.8744-bigger.hdf5\n",
      "Epoch 11/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.8597 - val_loss: 1.7194\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.74349 to 1.71936, saving model to weights-improvement-11-1.8585-bigger.hdf5\n",
      "Epoch 12/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.8451 - val_loss: 1.7133\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.71936 to 1.71329, saving model to weights-improvement-12-1.8429-bigger.hdf5\n",
      "Epoch 13/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.8289 - val_loss: 1.6999\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.71329 to 1.69989, saving model to weights-improvement-13-1.8291-bigger.hdf5\n",
      "Epoch 14/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.8177 - val_loss: 1.6910\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.69989 to 1.69102, saving model to weights-improvement-14-1.8169-bigger.hdf5\n",
      "Epoch 15/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.8065 - val_loss: 1.6882\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.69102 to 1.68823, saving model to weights-improvement-15-1.8070-bigger.hdf5\n",
      "Epoch 16/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7969 - val_loss: 1.6714\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.68823 to 1.67144, saving model to weights-improvement-16-1.7968-bigger.hdf5\n",
      "Epoch 17/50\n",
      "18859/18859 [==============================] - 283s 15ms/step - loss: 1.7884 - val_loss: 1.6651\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.67144 to 1.66512, saving model to weights-improvement-17-1.7881-bigger.hdf5\n",
      "Epoch 18/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7791 - val_loss: 1.6593\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.66512 to 1.65927, saving model to weights-improvement-18-1.7792-bigger.hdf5\n",
      "Epoch 19/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7695 - val_loss: 1.6548\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.65927 to 1.65478, saving model to weights-improvement-19-1.7714-bigger.hdf5\n",
      "Epoch 20/50\n",
      "18859/18859 [==============================] - 290s 15ms/step - loss: 1.7637 - val_loss: 1.6479\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.65478 to 1.64792, saving model to weights-improvement-20-1.7650-bigger.hdf5\n",
      "Epoch 21/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7568 - val_loss: 1.6408\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.64792 to 1.64076, saving model to weights-improvement-21-1.7580-bigger.hdf5\n",
      "Epoch 22/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7514 - val_loss: 1.6332\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.64076 to 1.63317, saving model to weights-improvement-22-1.7512-bigger.hdf5\n",
      "Epoch 23/50\n",
      "18859/18859 [==============================] - 284s 15ms/step - loss: 1.7451 - val_loss: 1.6230\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.63317 to 1.62299, saving model to weights-improvement-23-1.7458-bigger.hdf5\n",
      "Epoch 24/50\n",
      "18859/18859 [==============================] - 286s 15ms/step - loss: 1.7407 - val_loss: 1.6219\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.62299 to 1.62189, saving model to weights-improvement-24-1.7407-bigger.hdf5\n",
      "Epoch 25/50\n",
      "18859/18859 [==============================] - 286s 15ms/step - loss: 2.0849 - val_loss: 1.6362\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.62189\n",
      "Epoch 26/50\n",
      "18859/18859 [==============================] - 286s 15ms/step - loss: 1.7489 - val_loss: 1.6232\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.62189\n",
      "Epoch 27/50\n",
      "18859/18859 [==============================] - 286s 15ms/step - loss: 1.7326 - val_loss: 1.6190\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.62189 to 1.61904, saving model to weights-improvement-27-1.7331-bigger.hdf5\n",
      "Epoch 28/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.7246 - val_loss: 1.6098\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.61904 to 1.60980, saving model to weights-improvement-28-1.7271-bigger.hdf5\n",
      "Epoch 29/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.7204 - val_loss: 1.6095\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.60980 to 1.60955, saving model to weights-improvement-29-1.7212-bigger.hdf5\n",
      "Epoch 30/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.7152 - val_loss: 1.5989\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.60955 to 1.59889, saving model to weights-improvement-30-1.7166-bigger.hdf5\n",
      "Epoch 31/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.7111 - val_loss: 1.6026\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.59889\n",
      "Epoch 32/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 1.7414 - val_loss: 2.2800\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.59889\n",
      "Epoch 33/50\n",
      "18859/18859 [==============================] - 285s 15ms/step - loss: 2.1514 - val_loss: 1.7693\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.59889\n",
      "Epoch 34/50\n",
      "18859/18859 [==============================] - 286s 15ms/step - loss: 1.8724 - val_loss: 1.6987\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.59889\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # minibatch size\n",
    "num_epochs = 50 # number of epochs\n",
    "file_path=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "# added earlystopping to avoid overfitting\n",
    "callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
    "           ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')]\n",
    "#fit the model\n",
    "history = model.fit(X, y,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=num_epochs,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfIx1uPARlKa"
   },
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-30-1.7166-bigger.hdf5\"\n",
    "model.load_weights(filename) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H4CUS5xRtcV"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((ord(c), c) for c in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6UhZXvyeQrR",
    "outputId": "b16fb486-dbb3-4bc6-c644-bed7fb83a266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" introduction the present work is intended as an investigation of certain problems concerning empiri \"\n",
      "cal propositions and the semse if the semse if the semte is the semte if the semte is the semte if the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the semte is the semte if the semte is the semte if teet aelieve the semte if the semte if the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# testing model on first train data pt\n",
    "pattern = first_data_pt\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0tYmM0DD234"
   },
   "source": [
    "Use the network with the best weights to generate 1000 characters, using the\n",
    "following text as initialization of the network:<br>\n",
    "There are those who take mental phenomena naively, just as they\n",
    "would physical phenomena. This school of psychologists tends not to\n",
    "emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4XKIHCdTNHh",
    "outputId": "15bfa68f-89ab-4f79-b340-3fa355a09304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ust as they would physical phenomena this school of psychologists tends not to emphasize the object \"\n",
      " of the perception of the semse if the semse if the semte if the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtence is the semtenc\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "pattern = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "pattern = pattern.translate(str.maketrans('', '', string.punctuation))\n",
    "pattern = [char_to_int[c] for c in pattern[-99:].lower()]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmhAiQO7Gz49"
   },
   "source": [
    "**References**<br>\n",
    "https://wiki.pathmind.com/lstm<br>\n",
    "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/<br>\n",
    "https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/<br>\n",
    "https://towardsdatascience.com/long-short-term-memory-lstm-in-keras-2b5749e953ac"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DSCI_552_Lab7_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
